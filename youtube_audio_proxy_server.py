#!/usr/bin/env python3
"""
YouTube Audio Download Server
æœ¬åœ°ä¸‹è½½ç‰ˆæœ¬ - ä¸ºKumarajiva iOSåº”ç”¨æä¾›YouTubeéŸ³é¢‘æµæœ¬åœ°ä¸‹è½½æœåŠ¡

åŠŸèƒ½ç‰¹æ€§:
1. å®Œæ•´ä¸‹è½½mp3éŸ³é¢‘æ–‡ä»¶å’Œsrtè‹±æ–‡å­—å¹•æ–‡ä»¶åˆ°æœ¬åœ°
2. æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œä¸‹è½½ç®¡ç†
3. æä¾›HTTPæ–‡ä»¶æœåŠ¡ï¼Œæ”¯æŒRangeè¯·æ±‚
4. è‡ªåŠ¨ç¼“å­˜ç®¡ç†ï¼ˆ12å°æ—¶è¿‡æœŸ + LRUæ¸…ç†ï¼‰
5. ä¸‹è½½ä»»åŠ¡é˜Ÿåˆ—å’Œè¿›åº¦è·Ÿè¸ª
6. ä½¿ç”¨yt-dlpæ›¿ä»£YouTube Data API v3è·å–é¢‘é“å’Œè§†é¢‘ä¿¡æ¯

éƒ¨ç½²è¦æ±‚:
1. Python 3.8+
2. pip install flask yt-dlp

å¯åŠ¨å‘½ä»¤:
python3 youtube_audio_proxy_server.py

æœåŠ¡ç«¯å£: 5000
APIç«¯ç‚¹:
# ä¸‹è½½ç›¸å…³
- POST /download?id=VIDEO_ID    # å¼€å§‹ä¸‹è½½ä»»åŠ¡
- GET /status?id=VIDEO_ID       # è·å–ä¸‹è½½çŠ¶æ€
- GET /files/audio?id=VIDEO_ID  # è·å–éŸ³é¢‘æ–‡ä»¶
- GET /files/subtitle?id=VIDEO_ID # è·å–å­—å¹•æ–‡ä»¶
- GET /info?id=VIDEO_ID         # è·å–è§†é¢‘å…ƒæ•°æ®
- DELETE /cancel?id=VIDEO_ID    # å–æ¶ˆä¸‹è½½ä»»åŠ¡

# YouTubeæ•°æ®è·å–ï¼ˆæ›¿ä»£YouTube Data API v3ï¼‰
- GET /api/channel/info?id=CHANNEL_ID_OR_USERNAME     # è·å–é¢‘é“ä¿¡æ¯
- GET /api/channel/videos?id=CHANNEL_ID&limit=20      # è·å–é¢‘é“è§†é¢‘åˆ—è¡¨
- GET /api/video/info?id=VIDEO_ID                     # è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯
- GET /api/search/channel?q=QUERY                     # æœç´¢é¢‘é“
"""

import yt_dlp
from flask import Flask, Response, request, abort, jsonify, send_file
import urllib.request
import logging
import sys
import os
import json
import time
import threading
import hashlib
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Optional, Any, List
import uuid
from dataclasses import dataclass
from enum import Enum
import shutil
import mimetypes
import re

app = Flask(__name__)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('youtube_download.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# åˆ›å»ºä¸‹è½½ç›®å½•
DOWNLOAD_DIR = Path('./downloads')
DOWNLOAD_DIR.mkdir(exist_ok=True)

# åˆ›å»ºç¼“å­˜ç›®å½•ï¼ˆç”¨äºå­˜å‚¨é¢‘é“å’Œè§†é¢‘ä¿¡æ¯ï¼‰
CACHE_DIR = Path('./cache')
CACHE_DIR.mkdir(exist_ok=True)

# ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆ12å°æ—¶ï¼‰
CACHE_EXPIRE_HOURS = 12

# YouTube Cookies æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
COOKIES_FILE = Path('./youtube_cookies.txt')

# ä»»åŠ¡çŠ¶æ€æšä¸¾
class TaskStatus(Enum):
    PENDING = "pending"
    DOWNLOADING = "downloading"  
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class DownloadTask:
    task_id: str
    video_id: str
    status: TaskStatus
    progress: float
    message: str
    audio_file: Optional[str] = None
    subtitle_file: Optional[str] = None
    error: Optional[str] = None
    created_at: datetime = None
    completed_at: Optional[datetime] = None
    video_info: Optional[Dict] = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()

# å…¨å±€ä»»åŠ¡ç®¡ç†
tasks: Dict[str, DownloadTask] = {}
download_threads: Dict[str, threading.Thread] = {}

# =============================================================================
# YouTube æ•°æ®è·å–åŠŸèƒ½ï¼ˆæ›¿ä»£ YouTube Data API v3ï¼‰
# =============================================================================

def get_common_ydl_opts() -> dict:
    """è·å–é€šç”¨çš„ yt-dlp é…ç½®ï¼Œç”¨äºç»•è¿‡ YouTube 403 é”™è¯¯å’Œæœºå™¨äººéªŒè¯"""
    opts = {
        'extractor_args': {
            'youtube': {
                'player_client': ['android', 'web', 'tv', 'ios'],
                'player_skip': ['webpage', 'configs'],
                'skip_webpage': False,
                'ignore_signaling': True,
            }
        },
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-us,en;q=0.5',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-Dest': 'document',
            'Cache-Control': 'max-age=0',
            'Pragma': 'no-cache',
        },
        'socket_timeout': 30,
        'retries': 15,
        'fragment_retries': 15,
        'skip_unavailable_fragments': True,
        'allow_unplayable_formats': True,
        'extractor_retries': 5,
        'sleep_interval': 0.5,
        'max_sleep_interval': 2,
    }
    
    if COOKIES_FILE.exists():
        opts['cookiefile'] = str(COOKIES_FILE)
        logger.info(f"ğŸ“¦ ä½¿ç”¨ YouTube cookies æ–‡ä»¶: {COOKIES_FILE}")
    else:
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ° YouTube cookies æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
    
    return opts

def get_cache_path(cache_type: str, identifier: str) -> Path:
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    safe_id = hashlib.md5(identifier.encode()).hexdigest()[:12]
    return CACHE_DIR / f"{cache_type}_{safe_id}_{identifier.replace('/', '_')}.json"

def is_cache_valid(cache_path: Path) -> bool:
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆæœªè¿‡æœŸï¼‰"""
    if not cache_path.exists():
        return False
    
    file_time = datetime.fromtimestamp(cache_path.stat().st_mtime)
    return datetime.now() - file_time < timedelta(hours=CACHE_EXPIRE_HOURS)

def save_cache(cache_path: Path, data: dict):
    """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
    try:
        cache_path.parent.mkdir(exist_ok=True)
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.warning(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥ {cache_path}: {e}")

def load_cache(cache_path: Path) -> Optional[dict]:
    """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
    if not is_cache_valid(cache_path):
        return None
    
    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"âš ï¸ è¯»å–ç¼“å­˜å¤±è´¥ {cache_path}: {e}")
        return None

def resolve_channel_id(input_str: str) -> str:
    """è§£æé¢‘é“IDï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼"""
    logger.info(f"ğŸ” è§£æé¢‘é“æ ‡è¯†: {input_str}")
    
    # å»é™¤ @ å‰ç¼€
    if input_str.startswith('@'):
        input_str = input_str[1:]
    
    # å¦‚æœå·²ç»æ˜¯é¢‘é“IDæ ¼å¼ï¼ˆUCå¼€å¤´ä¸”é•¿åº¦ä¸º24ï¼‰ï¼Œç›´æ¥è¿”å›
    if input_str.startswith('UC') and len(input_str) == 24:
        logger.info(f"âœ… è¯†åˆ«ä¸ºé¢‘é“ID: {input_str}")
        return input_str
    
    # æ£€æŸ¥ç¼“å­˜
    cache_path = get_cache_path("channel_resolve", input_str)
    cached_data = load_cache(cache_path)
    if cached_data and 'channel_id' in cached_data:
        logger.info(f"ğŸ“¦ ä»ç¼“å­˜è·å–é¢‘é“ID: {cached_data['channel_id']}")
        return cached_data['channel_id']
    
    try:
        # ä½¿ç”¨yt-dlpè·å–é¢‘é“ä¿¡æ¯
        ydl_opts = {
            'quiet': True,
            'skip_download': True,
            'extract_flat': True,
            'playlist_items': '1',  # åªè·å–ä¸€ä¸ªè§†é¢‘æ¥å¾—åˆ°é¢‘é“ID
            **get_common_ydl_opts(),  # æ·»åŠ é€šç”¨é…ç½®
        }
        
        # å°è¯•ä¸åŒçš„URLæ ¼å¼
        possible_urls = [
            f'https://www.youtube.com/@{input_str}',
            f'https://www.youtube.com/c/{input_str}', 
            f'https://www.youtube.com/user/{input_str}',
            f'https://www.youtube.com/channel/{input_str}',
        ]
        
        for url in possible_urls:
            try:
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(url, download=False)
                    
                    if info and 'channel_id' in info:
                        channel_id = info['channel_id']
                        logger.info(f"âœ… é€šè¿‡URL {url} è·å–åˆ°é¢‘é“ID: {channel_id}")
                        
                        # ä¿å­˜åˆ°ç¼“å­˜
                        save_cache(cache_path, {'channel_id': channel_id, 'resolved_from': url})
                        return channel_id
                        
            except Exception as e:
                logger.debug(f"ğŸ” å°è¯•URLå¤±è´¥ {url}: {e}")
                continue
        
        raise Exception(f"æ— æ³•è§£æé¢‘é“æ ‡è¯†: {input_str}")
        
    except Exception as e:
        logger.error(f"âŒ é¢‘é“IDè§£æå¤±è´¥: {e}")
        raise Exception(f"é¢‘é“ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {input_str}")

def get_channel_info(channel_input: str) -> dict:
    """è·å–é¢‘é“ä¿¡æ¯"""
    logger.info(f"ğŸ“º è·å–é¢‘é“ä¿¡æ¯: {channel_input}")
    
    # è§£æé¢‘é“ID
    channel_id = resolve_channel_id(channel_input)
    
    # æ£€æŸ¥ç¼“å­˜
    cache_path = get_cache_path("channel_info", channel_id)
    cached_data = load_cache(cache_path)
    if cached_data:
        logger.info(f"ğŸ“¦ ä»ç¼“å­˜è·å–é¢‘é“ä¿¡æ¯: {cached_data.get('title', 'Unknown')}")
        return cached_data
    
    try:
        ydl_opts = {
            'quiet': True,
            'skip_download': True,
            'extract_flat': False,
            'playlist_items': '1:5',  # è·å–å‰5ä¸ªè§†é¢‘æ¥å¾—åˆ°é¢‘é“è¯¦ç»†ä¿¡æ¯
            **get_common_ydl_opts(),  # æ·»åŠ é€šç”¨é…ç½®
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(f'https://www.youtube.com/channel/{channel_id}/videos', download=False)
            
            if not info:
                raise Exception("æ— æ³•è·å–é¢‘é“ä¿¡æ¯")
            
            # æå–é¢‘é“ä¿¡æ¯
            channel_info = {
                'channel_id': channel_id,
                'title': info.get('title', ''),
                'description': (info.get('description', '') or '')[:500],
                'subscriber_count': info.get('subscriber_count'),
                'video_count': len(info.get('entries', [])) if 'entries' in info else 0,
                'thumbnail': info.get('thumbnail') or (info.get('thumbnails', [{}])[-1].get('url', '') if info.get('thumbnails') else ''),
                'uploader': info.get('uploader', info.get('title', '')),
                'webpage_url': f'https://www.youtube.com/channel/{channel_id}',
                'updated_at': datetime.now().isoformat()
            }
            
            # å¤„ç†ç¼©ç•¥å›¾
            if not channel_info['thumbnail'] and 'entries' in info and info['entries']:
                # å¦‚æœæ²¡æœ‰é¢‘é“ç¼©ç•¥å›¾ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„ç¼©ç•¥å›¾
                first_video = info['entries'][0]
                if 'thumbnails' in first_video and first_video['thumbnails']:
                    channel_info['thumbnail'] = first_video['thumbnails'][-1].get('url', '')
            
            logger.info(f"âœ… è·å–é¢‘é“ä¿¡æ¯æˆåŠŸ: {channel_info['title']}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            save_cache(cache_path, channel_info)
            
            return channel_info
            
    except Exception as e:
        logger.error(f"âŒ è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
        raise Exception(f"è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {str(e)}")

def get_channel_videos(channel_input: str, limit: int = 20) -> List[dict]:
    """è·å–é¢‘é“è§†é¢‘åˆ—è¡¨"""
    logger.info(f"ğŸ¬ è·å–é¢‘é“è§†é¢‘: {channel_input}, æ•°é‡é™åˆ¶: {limit}")
    
    # è§£æé¢‘é“ID
    channel_id = resolve_channel_id(channel_input)
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"{channel_id}_{limit}"
    cache_path = get_cache_path("channel_videos", cache_key)
    cached_data = load_cache(cache_path)
    if cached_data:
        logger.info(f"ğŸ“¦ ä»ç¼“å­˜è·å–é¢‘é“è§†é¢‘: {len(cached_data)} ä¸ªè§†é¢‘")
        return cached_data
    
    try:
        ydl_opts = {
            'quiet': True,
            'skip_download': True,
            'extract_flat': True,
            'playlist_items': f'1:{limit}',
            **get_common_ydl_opts(),  # æ·»åŠ é€šç”¨é…ç½®
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(f'https://www.youtube.com/channel/{channel_id}/videos', download=False)
            
            if not info or 'entries' not in info:
                logger.warning(f"âš ï¸ é¢‘é“æ— è§†é¢‘æˆ–æ— æ³•è®¿é—®: {channel_id}")
                return []
            
            videos = []
            for entry in info['entries'][:limit]:
                if not entry:
                    continue
                    
                video_info = {
                    'video_id': entry.get('id', ''),
                    'title': entry.get('title', ''),
                    'description': (entry.get('description', '') or '')[:200],
                    'duration': entry.get('duration', 0),
                    'upload_date': entry.get('upload_date', ''),
                    'view_count': entry.get('view_count', 0),
                    'thumbnail': '',
                    'webpage_url': entry.get('webpage_url', f"https://www.youtube.com/watch?v={entry.get('id', '')}")
                }
                
                # å¤„ç†ç¼©ç•¥å›¾
                if 'thumbnails' in entry and entry['thumbnails']:
                    video_info['thumbnail'] = entry['thumbnails'][-1].get('url', '')
                elif entry.get('id'):
                    # ä½¿ç”¨æ ‡å‡†çš„YouTubeç¼©ç•¥å›¾URL
                    video_info['thumbnail'] = f"https://img.youtube.com/vi/{entry['id']}/maxresdefault.jpg"
                
                videos.append(video_info)
            
            logger.info(f"âœ… è·å–é¢‘é“è§†é¢‘æˆåŠŸ: {len(videos)} ä¸ªè§†é¢‘")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            save_cache(cache_path, videos)
            
            return videos
            
    except Exception as e:
        logger.error(f"âŒ è·å–é¢‘é“è§†é¢‘å¤±è´¥: {e}")
        raise Exception(f"è·å–é¢‘é“è§†é¢‘å¤±è´¥: {str(e)}")

def get_video_info_detailed(video_id: str) -> dict:
    """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼ˆæ¯”åŸºç¡€çš„get_video_infoæ›´è¯¦ç»†ï¼‰"""
    logger.info(f"ğŸ¥ è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯: {video_id}")
    
    # æ£€æŸ¥ç¼“å­˜
    cache_path = get_cache_path("video_detailed", video_id)
    cached_data = load_cache(cache_path)
    if cached_data:
        logger.info(f"ğŸ“¦ ä»ç¼“å­˜è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯: {cached_data.get('title', 'Unknown')}")
        return cached_data
    
    try:
        ydl_opts = {
            'quiet': True,
            'skip_download': True,
            'extract_flat': False,
            'noplaylist': True,
            **get_common_ydl_opts(),  # æ·»åŠ é€šç”¨é…ç½®
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(f'https://www.youtube.com/watch?v={video_id}', download=False)
            
            if not info:
                raise Exception("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
            
            # æå–è¯¦ç»†è§†é¢‘ä¿¡æ¯
            video_info = {
                'id': video_id,  # iOSç«¯æœŸæœ›å­—æ®µåä¸º'id'
                'title': info.get('title', ''),
                'description': (info.get('description', '') or '')[:500],
                'duration': info.get('duration', 0),
                'uploader': info.get('uploader', ''),
                'channel_id': info.get('channel_id', ''),
                'channel': info.get('channel', ''),
                'view_count': info.get('view_count', 0),
                'like_count': info.get('like_count', 0),
                'upload_date': info.get('upload_date', ''),
                'webpage_url': info.get('webpage_url', ''),
                'thumbnail': '',
                'updated_at': datetime.now().isoformat()
            }
            
            # å¤„ç†ç¼©ç•¥å›¾
            if 'thumbnails' in info and info['thumbnails']:
                video_info['thumbnail'] = info['thumbnails'][-1].get('url', '')
            else:
                video_info['thumbnail'] = f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg"
            
            logger.info(f"âœ… è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯æˆåŠŸ: {video_info['title']}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            save_cache(cache_path, video_info)
            
            return video_info
            
    except Exception as e:
        logger.error(f"âŒ è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
        raise Exception(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")

def search_channels(query: str, limit: int = 10) -> List[dict]:
    """æœç´¢é¢‘é“"""
    logger.info(f"ğŸ” æœç´¢é¢‘é“: {query}, é™åˆ¶: {limit}")
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"{query}_{limit}"
    cache_path = get_cache_path("search_channels", cache_key)
    cached_data = load_cache(cache_path)
    if cached_data:
        logger.info(f"ğŸ“¦ ä»ç¼“å­˜è·å–æœç´¢ç»“æœ: {len(cached_data)} ä¸ªé¢‘é“")
        return cached_data
    
    try:
        ydl_opts = {
            'quiet': True,
            'skip_download': True,
            'extract_flat': True,
            'playlist_items': f'1:{limit}',
            **get_common_ydl_opts(),  # æ·»åŠ é€šç”¨é…ç½®
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # æœç´¢é¢‘é“
            search_url = f'ytsearch{limit}:"{query}" channel'
            info = ydl.extract_info(search_url, download=False)
            
            if not info or 'entries' not in info:
                logger.warning(f"âš ï¸ æœç´¢æ— ç»“æœ: {query}")
                return []
            
            channels = []
            seen_channels = set()  # é¿å…é‡å¤
            
            for entry in info['entries']:
                if not entry or not entry.get('channel_id'):
                    continue
                
                channel_id = entry['channel_id']
                if channel_id in seen_channels:
                    continue
                seen_channels.add(channel_id)
                
                channel_info = {
                    'channel_id': channel_id,
                    'title': entry.get('channel', entry.get('uploader', '')),
                    'description': (entry.get('description', '') or '')[:200],
                    'thumbnail': '',
                    'subscriber_count': None,
                    'video_count': None,
                    'webpage_url': f'https://www.youtube.com/channel/{channel_id}'
                }
                
                # å¤„ç†ç¼©ç•¥å›¾
                if 'thumbnails' in entry and entry['thumbnails']:
                    channel_info['thumbnail'] = entry['thumbnails'][-1].get('url', '')
                
                channels.append(channel_info)
            
            logger.info(f"âœ… æœç´¢é¢‘é“æˆåŠŸ: {len(channels)} ä¸ªç»“æœ")
            
            # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆæœç´¢ç»“æœç¼“å­˜æ—¶é—´è¾ƒçŸ­ï¼Œ1å°æ—¶ï¼‰
            save_cache(cache_path, channels)
            
            return channels
            
    except Exception as e:
        logger.error(f"âŒ æœç´¢é¢‘é“å¤±è´¥: {e}")
        raise Exception(f"æœç´¢å¤±è´¥: {str(e)}")

# =============================================================================
# æ–°å¢APIç«¯ç‚¹ï¼ˆYouTubeæ•°æ®è·å–ï¼‰
# =============================================================================

@app.route('/api/channel/info')
def api_get_channel_info():
    """è·å–é¢‘é“ä¿¡æ¯API"""
    channel_input = request.args.get('id')
    if not channel_input:
        return jsonify({"error": "Missing channel id or username"}), 400
    
    try:
        channel_info = get_channel_info(channel_input)
        return jsonify(channel_info)
    except Exception as e:
        logger.error(f"âŒ é¢‘é“ä¿¡æ¯APIé”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 400

@app.route('/api/channel/videos')
def api_get_channel_videos():
    """è·å–é¢‘é“è§†é¢‘åˆ—è¡¨API"""
    channel_input = request.args.get('id')
    if not channel_input:
        return jsonify({"error": "Missing channel id"}), 400
    
    limit = request.args.get('limit', 20)
    try:
        limit = int(limit)
        limit = max(1, min(limit, 50))  # é™åˆ¶åœ¨1-50ä¹‹é—´
    except ValueError:
        limit = 20
    
    try:
        videos = get_channel_videos(channel_input, limit)
        return jsonify({
            "videos": videos,
            "count": len(videos)
        })
    except Exception as e:
        logger.error(f"âŒ é¢‘é“è§†é¢‘APIé”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 400

@app.route('/api/video/info')
def api_get_video_info():
    """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯API"""
    video_id = request.args.get('id')
    if not video_id:
        return jsonify({"error": "Missing video id"}), 400
    
    try:
        video_info = get_video_info_detailed(video_id)
        return jsonify(video_info)
    except Exception as e:
        logger.error(f"âŒ è§†é¢‘ä¿¡æ¯APIé”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 400

@app.route('/api/search/channel')
def api_search_channels():
    """æœç´¢é¢‘é“API"""
    query = request.args.get('q')
    if not query:
        return jsonify({"error": "Missing search query"}), 400
    
    limit = request.args.get('limit', 10)
    try:
        limit = int(limit)
        limit = max(1, min(limit, 20))  # é™åˆ¶åœ¨1-20ä¹‹é—´
    except ValueError:
        limit = 10
    
    try:
        channels = search_channels(query, limit)
        return jsonify({
            "channels": channels,
            "count": len(channels),
            "query": query
        })
    except Exception as e:
        logger.error(f"âŒ æœç´¢é¢‘é“APIé”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 400

# =============================================================================
# åŸæœ‰çš„æ–‡ä»¶ç®¡ç†å’Œä¸‹è½½åŠŸèƒ½ä¿æŒä¸å˜
# =============================================================================

# æ–‡ä»¶ç®¡ç†
def get_file_path(video_id: str, file_type: str) -> Path:
    """è·å–æ–‡ä»¶è·¯å¾„"""
    safe_id = hashlib.md5(video_id.encode()).hexdigest()[:12]
    if file_type == "audio":
        return DOWNLOAD_DIR / f"{safe_id}_{video_id}.mp3"
    elif file_type == "subtitle":
        return DOWNLOAD_DIR / f"{safe_id}_{video_id}.vtt"
    elif file_type == "info":
        return DOWNLOAD_DIR / f"{safe_id}_{video_id}.json"
    else:
        raise ValueError(f"Unknown file type: {file_type}")

def find_actual_audio_file(video_id: str) -> Optional[Path]:
    """æŸ¥æ‰¾å®é™…å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œç»Ÿä¸€é€»è¾‘é¿å…é‡å¤ä»£ç """
    # é¦–å…ˆæ£€æŸ¥ä»»åŠ¡ä¸­è®°å½•çš„å®é™…æ–‡ä»¶è·¯å¾„
    if video_id in tasks:
        task = tasks[video_id]
        if task.audio_file and Path(task.audio_file).exists():
            actual_file = Path(task.audio_file)
            if actual_file.stat().st_size > 0:
                return actual_file
    
    # æ£€æŸ¥é»˜è®¤è·¯å¾„
    default_audio_file = get_file_path(video_id, "audio")
    if default_audio_file.exists() and default_audio_file.stat().st_size > 0:
        return default_audio_file
    
    # å°è¯•æŸ¥æ‰¾å®é™…å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶
    base_path = default_audio_file.with_suffix('')
    possible_files = [
        base_path,  # æ— æ‰©å±•åæ–‡ä»¶
        Path(str(base_path) + '.m4a'),
        Path(str(base_path) + '.mp4'),
        Path(str(base_path) + '.aac'),
        Path(str(base_path) + '.webm'),
        Path(str(base_path) + '.mp3')
    ]
    
    for candidate in possible_files:
        if candidate.exists() and candidate.stat().st_size > 0:
            return candidate
    
    return None

def cleanup_old_files():
    """æ¸…ç†è¿‡æœŸæ–‡ä»¶ï¼ˆ12å°æ—¶ï¼‰ï¼Œå¢å¼ºä¿æŠ¤æœºåˆ¶é¿å…åˆ é™¤ä»åœ¨ä½¿ç”¨çš„æ–‡ä»¶"""
    try:
        cutoff_time = datetime.now() - timedelta(hours=CACHE_EXPIRE_HOURS)
        cleaned_count = 0
        
        # æ”¶é›†å½“å‰æ‰€æœ‰ä»»åŠ¡ä¸­è®°å½•çš„æ–‡ä»¶è·¯å¾„ï¼ˆæ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶ï¼‰
        protected_files = set()
        for video_id, task in tasks.items():
            if task.audio_file:
                protected_files.add(Path(task.audio_file).resolve())
            if task.subtitle_file:
                protected_files.add(Path(task.subtitle_file).resolve())
        
        # æ¸…ç†ä¸‹è½½æ–‡ä»¶
        for file_path in DOWNLOAD_DIR.glob("*"):
            if file_path.is_file():
                # é¢å¤–ä¿æŠ¤ï¼šè·³è¿‡æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶
                if file_path.resolve() in protected_files:
                    logger.info(f"ğŸ›¡ï¸ è·³è¿‡æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶: {file_path.name}")
                    continue
                    
                file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_time < cutoff_time:
                    try:
                        file_path.unlink()
                        cleaned_count += 1
                        logger.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸä¸‹è½½æ–‡ä»¶: {file_path.name}")
                    except Exception as e:
                        logger.error(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æ¸…ç†ç¼“å­˜æ–‡ä»¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        for file_path in CACHE_DIR.glob("*"):
            if file_path.is_file():
                file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_time < cutoff_time:
                    try:
                        file_path.unlink()
                        cleaned_count += 1
                        logger.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸç¼“å­˜æ–‡ä»¶: {file_path.name}")
                    except Exception as e:
                        logger.error(f"âŒ åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æ¸…ç†æ—§çš„ä»»åŠ¡è®°å½•ï¼ˆé¿å…å†…å­˜ç§¯ç´¯ï¼‰
        cleaned_tasks = cleanup_old_tasks()
        
        if cleaned_count > 0 or cleaned_tasks > 0:
            logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆ: åˆ é™¤äº† {cleaned_count} ä¸ªè¿‡æœŸæ–‡ä»¶ï¼Œ{cleaned_tasks} ä¸ªæ—§ä»»åŠ¡è®°å½•")
            logger.info(f"ğŸ›¡ï¸ ä¿æŠ¤äº† {len(protected_files)} ä¸ªæ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶")
        
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")

def cleanup_old_tasks():
    """æ¸…ç†æ—§çš„ä»»åŠ¡è®°å½•ï¼Œé¿å…å†…å­˜ç§¯ç´¯"""
    try:
        cutoff_time = datetime.now() - timedelta(hours=CACHE_EXPIRE_HOURS)
        tasks_to_remove = []
        
        for video_id, task in tasks.items():
            # æ¸…ç†è¶…è¿‡12å°æ—¶çš„å·²å®Œæˆã€å¤±è´¥æˆ–å–æ¶ˆçš„ä»»åŠ¡
            if task.status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]:
                if task.created_at and datetime.now() - task.created_at > timedelta(hours=CACHE_EXPIRE_HOURS):
                    tasks_to_remove.append(video_id)
                elif task.completed_at and datetime.now() - task.completed_at > timedelta(hours=CACHE_EXPIRE_HOURS):
                    tasks_to_remove.append(video_id)
        
        # åˆ é™¤æ—§ä»»åŠ¡è®°å½•
        for video_id in tasks_to_remove:
            try:
                del tasks[video_id]
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†æ—§ä»»åŠ¡è®°å½•: {video_id}")
            except KeyError:
                pass  # ä»»åŠ¡å·²è¢«å…¶ä»–åœ°æ–¹åˆ é™¤
        
        return len(tasks_to_remove)
        
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡æ¸…ç†å¤±è´¥: {e}")
        return 0

def check_existing_files(video_id: str) -> Dict[str, bool]:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ•ˆï¼ˆä¸æ£€æŸ¥è¿‡æœŸæ—¶é—´ï¼‰"""
    result = {
        "audio": False,
        "subtitle": False,
        "info": False
    }
    
    for file_type in result.keys():
        file_path = get_file_path(video_id, file_type)
        
        if file_type == "audio":
            actual_audio_file = find_actual_audio_file(video_id)
            if actual_audio_file:
                result[file_type] = True
        else:
            # ééŸ³é¢‘æ–‡ä»¶ä½¿ç”¨åŸæœ‰é€»è¾‘
            if file_path.exists() and file_path.stat().st_size > 0:
                result[file_type] = True
    
    logger.info(f"ğŸ¯ æ–‡ä»¶æ£€æŸ¥ç»“æœ {video_id}: audio={result['audio']}, subtitle={result['subtitle']}")
    return result

def get_video_info(video_id: str) -> Optional[Dict]:
    """è·å–è§†é¢‘ä¿¡æ¯ï¼ˆä»ç¼“å­˜æˆ–ç½‘ç»œï¼‰"""
    info_file = get_file_path(video_id, "info")
    
    # å°è¯•ä»ç¼“å­˜è¯»å–
    if info_file.exists():
        try:
            with open(info_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ è¯»å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
    
    # ä»ç½‘ç»œè·å–ï¼ˆä½¿ç”¨æ–°çš„è¯¦ç»†ä¿¡æ¯è·å–å‡½æ•°ï¼‰
    try:
        video_info = get_video_info_detailed(video_id)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        try:
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(video_info, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜è§†é¢‘ä¿¡æ¯ç¼“å­˜å¤±è´¥: {e}")
        
        return video_info
        
    except Exception as e:
        logger.error(f"âŒ è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return None

def download_files(task: DownloadTask):
    """ä¸‹è½½éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶"""
    try:
        logger.info(f"ğŸµ å¼€å§‹ä¸‹è½½ä»»åŠ¡: {task.video_id}")
        task.status = TaskStatus.DOWNLOADING
        task.progress = 0.0
        task.message = "å‡†å¤‡ä¸‹è½½..."
        
        # è·å–è§†é¢‘ä¿¡æ¯
        task.video_info = get_video_info(task.video_id)
        if not task.video_info:
            raise Exception("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
        
        task.progress = 0.1
        task.message = "è·å–ä¸‹è½½é“¾æ¥..."
        
        audio_file = get_file_path(task.video_id, "audio")
        subtitle_file = get_file_path(task.video_id, "subtitle")
        
        # åˆ›å»ºyt-dlpé€‰é¡¹
        def progress_hook(d):
            if d['status'] == 'downloading':
                if 'total_bytes' in d and d['total_bytes']:
                    task.progress = 0.1 + 0.8 * (d['downloaded_bytes'] / d['total_bytes'])
                elif 'total_bytes_estimate' in d and d['total_bytes_estimate']:
                    task.progress = 0.1 + 0.8 * (d['downloaded_bytes'] / d['total_bytes_estimate'])
                else:
                    # æ— æ³•è·å–æ€»å¤§å°æ—¶çš„è¿›åº¦ä¼°ç®—
                    task.progress = min(0.9, task.progress + 0.01)
                
                task.message = f"ä¸‹è½½ä¸­... {d.get('_percent_str', 'N/A')}"
                logger.info(f"ğŸ“Š {task.video_id}: {task.message}")
                
            elif d['status'] == 'finished':
                task.progress = 0.9
                task.message = "ä¸‹è½½å®Œæˆï¼Œå¤„ç†ä¸­..."
                logger.info(f"âœ… {task.video_id}: æ–‡ä»¶ä¸‹è½½å®Œæˆ")

        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': str(audio_file.with_suffix('.%(ext)s')),
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['en'],
            'subtitlesformat': 'vtt',
            'writeinfojson': True,
            'extract_audio': True,
            'audio_format': 'mp3',
            'audio_quality': '128k',
            'prefer_ffmpeg': True,
            'noplaylist': True,
            'ignoreerrors': False,
            'no_warnings': True,
            'quiet': True,
            'progress_hooks': [lambda d: progress_hook(d)],
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '128',
            }],
            **get_common_ydl_opts(),
        }
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ
        if task.status == TaskStatus.CANCELLED:
            logger.info(f"âš ï¸ ä»»åŠ¡å·²å–æ¶ˆ: {task.video_id}")
            return
        
        # æ‰§è¡Œä¸‹è½½
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([f'https://www.youtube.com/watch?v={task.video_id}'])
        
        # éªŒè¯æ–‡ä»¶ - æ£€æŸ¥å®é™…ä¸‹è½½çš„æ–‡ä»¶
        # yt-dlpå¯èƒ½ä¼šä¸‹è½½ä¸åŒçš„æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦æŸ¥æ‰¾å®é™…çš„æ–‡ä»¶
        base_path = audio_file.with_suffix('')  # æ— æ‰©å±•åçš„åŸºç¡€è·¯å¾„
        actual_audio_file = None
        
        # å¸¸è§çš„éŸ³é¢‘æ–‡ä»¶æ‰©å±•åï¼ŒåŒ…æ‹¬æ— æ‰©å±•å
        possible_files = [
            base_path,  # æ— æ‰©å±•åæ–‡ä»¶
            Path(str(base_path) + '.m4a'),
            Path(str(base_path) + '.mp4'),
            Path(str(base_path) + '.aac'),
            Path(str(base_path) + '.webm'),
            Path(str(base_path) + '.mp3')
        ]
        
        for candidate in possible_files:
            if candidate.exists() and candidate.stat().st_size > 0:
                actual_audio_file = candidate
                break
        
        if not actual_audio_file:
            raise Exception("éŸ³é¢‘æ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–ä¸ºç©º")
        
        # å¦‚æœæ–‡ä»¶æ²¡æœ‰æ‰©å±•åï¼Œæ ¹æ®å†…å®¹æˆ–é»˜è®¤æ·»åŠ .mp3æ‰©å±•å
        target_audio_file = audio_file  # ç›®æ ‡æ–‡ä»¶åï¼ˆå¸¦.mp3æ‰©å±•åï¼‰
        
        if actual_audio_file != target_audio_file:
            try:
                # é‡å‘½åä¸ºå¸¦æ‰©å±•åçš„æ–‡ä»¶
                shutil.move(str(actual_audio_file), str(target_audio_file))
                logger.info(f"âœ… éŸ³é¢‘æ–‡ä»¶é‡å‘½å: {actual_audio_file.name} -> {target_audio_file.name}")
                actual_audio_file = target_audio_file
            except Exception as e:
                logger.warning(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶é‡å‘½åå¤±è´¥: {e}")
                # å¦‚æœé‡å‘½åå¤±è´¥ï¼Œä½¿ç”¨å®é™…æ–‡ä»¶
                pass
        
        task.audio_file = str(actual_audio_file)
        logger.info(f"ğŸµ éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {actual_audio_file.name} ({actual_audio_file.stat().st_size / 1024 / 1024:.1f} MB)")
        
        # æ£€æŸ¥å­—å¹•æ–‡ä»¶ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
        # å­—å¹•æ–‡ä»¶ä¹Ÿå¯èƒ½æœ‰ä¸åŒçš„æ‰©å±•å
        subtitle_base = subtitle_file.with_suffix('')  # æ— æ‰©å±•åçš„åŸºç¡€è·¯å¾„
        subtitle_candidates = [
            subtitle_file,  # .vtt
            Path(str(subtitle_base) + '.en.vtt'),  # .en.vtt
            Path(str(subtitle_base) + '.srt'),  # å¤‡ç”¨.srt
            Path(str(subtitle_base) + '.en.srt'),  # å¤‡ç”¨.en.srt
        ]
        
        actual_subtitle_file = None
        for candidate in subtitle_candidates:
            if candidate.exists() and candidate.stat().st_size > 0:
                actual_subtitle_file = candidate
                break
        
        if actual_subtitle_file:
            # å¦‚æœæ‰¾åˆ°çš„å­—å¹•æ–‡ä»¶åä¸é¢„æœŸä¸åŒï¼Œé‡å‘½åä¸ºé¢„æœŸçš„.vttæ ¼å¼
            if actual_subtitle_file != subtitle_file:
                try:
                    shutil.move(str(actual_subtitle_file), str(subtitle_file))
                    logger.info(f"âœ… å­—å¹•æ–‡ä»¶é‡å‘½å: {actual_subtitle_file.name} -> {subtitle_file.name}")
                    # æ›´æ–°ä¸ºé‡å‘½ååçš„æ–‡ä»¶è·¯å¾„
                    actual_subtitle_file = subtitle_file
                except Exception as e:
                    logger.warning(f"âš ï¸ å­—å¹•æ–‡ä»¶é‡å‘½åå¤±è´¥: {e}")
            
            logger.info(f"âœ… å­—å¹•æ–‡ä»¶éªŒè¯é€šè¿‡: {actual_subtitle_file.name}")
            task.subtitle_file = str(actual_subtitle_file)
            logger.info(f"ğŸ“ å­—å¹•æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {actual_subtitle_file.name} ({actual_subtitle_file.stat().st_size / 1024:.1f} KB)")
        else:
            logger.info(f"âš ï¸ æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
        
        # å®Œæˆ
        task.status = TaskStatus.COMPLETED
        task.progress = 1.0
        task.message = "ä¸‹è½½å®Œæˆ"
        task.completed_at = datetime.now()
        
        logger.info(f"âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆ: {task.video_id}")
        
    except Exception as e:
        if task.status != TaskStatus.CANCELLED:
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.message = f"ä¸‹è½½å¤±è´¥: {str(e)}"
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥ {task.video_id}: {e}")
    
    finally:
        # æ¸…ç†çº¿ç¨‹å¼•ç”¨
        if task.video_id in download_threads:
            del download_threads[task.video_id]

# API ç«¯ç‚¹

@app.route('/download', methods=['POST'])
def start_download():
    """å¼€å§‹ä¸‹è½½ä»»åŠ¡"""
    video_id = request.args.get('id')
    if not video_id:
        return jsonify({"error": "Missing video id"}), 400
    
    logger.info(f"ğŸš€ æ”¶åˆ°ä¸‹è½½è¯·æ±‚: {video_id}")
    
    # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ•ˆ
    existing_files = check_existing_files(video_id)
    if existing_files["audio"]:
        logger.info(f"âœ… éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›: {video_id}")
        
        # ğŸ”§ ä¿®å¤: ä½¿ç”¨ç»Ÿä¸€çš„æŸ¥æ‰¾é€»è¾‘è·å–å®é™…æ–‡ä»¶è·¯å¾„
        actual_audio_file = find_actual_audio_file(video_id)
        actual_audio_file_path = str(actual_audio_file) if actual_audio_file else None
        
        # æŸ¥æ‰¾å­—å¹•æ–‡ä»¶
        actual_subtitle_file_path = None
        if existing_files["subtitle"]:
            subtitle_file = get_file_path(video_id, "subtitle")
            if subtitle_file.exists():
                actual_subtitle_file_path = str(subtitle_file)
        
        # åˆ›å»ºæˆ–æ›´æ–°å·²å®Œæˆçš„ä»»åŠ¡è®°å½•
        task = DownloadTask(
            task_id=str(uuid.uuid4()),
            video_id=video_id,
            status=TaskStatus.COMPLETED,
            progress=1.0,
            message="æ–‡ä»¶å·²å­˜åœ¨",
            audio_file=actual_audio_file_path,  # ä½¿ç”¨å®é™…æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„
            subtitle_file=actual_subtitle_file_path,  # ä½¿ç”¨å®é™…æ‰¾åˆ°çš„å­—å¹•è·¯å¾„
            video_info=get_video_info(video_id)
        )
        tasks[video_id] = task
        return jsonify({
            "task_id": task.task_id,
            "status": task.status.value,
            "message": task.message,
            "files_ready": True
        })
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡
    if video_id in tasks:
        existing_task = tasks[video_id]
        
        # å¦‚æœä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¿”å›ä»»åŠ¡ä¿¡æ¯
        if existing_task.status in [TaskStatus.PENDING, TaskStatus.DOWNLOADING]:
            logger.info(f"âš ï¸ ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­: {video_id}")
            return jsonify({
                "task_id": existing_task.task_id,
                "status": existing_task.status.value,
                "message": "ä»»åŠ¡å·²åœ¨è¿›è¡Œä¸­"
            })
        
        # æ¸…ç†å¤±è´¥æˆ–å–æ¶ˆçš„ä»»åŠ¡è®°å½•
        elif existing_task.status in [TaskStatus.FAILED, TaskStatus.CANCELLED]:
            logger.info(f"ğŸ”„ æ¸…ç†å¤±è´¥/å–æ¶ˆçš„ä»»åŠ¡ï¼Œé‡æ–°å¼€å§‹: {video_id}")
            del tasks[video_id]
    
    # åˆ›å»ºæ–°çš„ä¸‹è½½ä»»åŠ¡
    logger.info(f"ğŸ¬ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹æ–°çš„ä¸‹è½½ä»»åŠ¡: {video_id}")
    task = DownloadTask(
        task_id=str(uuid.uuid4()),
        video_id=video_id,
        status=TaskStatus.PENDING,
        progress=0.0,
        message="ä»»åŠ¡å·²åˆ›å»º"
    )
    
    tasks[video_id] = task
    
    # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
    thread = threading.Thread(target=download_files, args=(task,))
    download_threads[video_id] = thread
    thread.start()
    
    logger.info(f"ğŸ¬ ä¸‹è½½ä»»åŠ¡å·²å¯åŠ¨: {video_id}")
    
    return jsonify({
        "task_id": task.task_id,
        "status": task.status.value,
        "message": task.message
    })

@app.route('/status')
def get_status():
    """è·å–ä¸‹è½½çŠ¶æ€"""
    video_id = request.args.get('id')
    if not video_id:
        return jsonify({"error": "Missing video id"}), 400
    
    if video_id not in tasks:
        return jsonify({"error": "Task not found"}), 404
    
    task = tasks[video_id]
    
    response = {
        "task_id": task.task_id,
        "video_id": task.video_id,
        "status": task.status.value,
        "progress": task.progress,
        "message": task.message,
        "created_at": task.created_at.isoformat(),
        "files_ready": task.status == TaskStatus.COMPLETED
    }
    
    if task.status == TaskStatus.COMPLETED:
        response.update({
            "completed_at": task.completed_at.isoformat() if task.completed_at else None,
            "has_audio": task.audio_file is not None,
            "has_subtitle": task.subtitle_file is not None,
            "video_info": task.video_info
        })
    
    if task.status == TaskStatus.FAILED and task.error:
        response["error"] = task.error
    
    return jsonify(response)

def get_file_mime_type(file_path: Path) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åå’Œå†…å®¹æ£€æµ‹MIMEç±»å‹"""
    # é¦–å…ˆå°è¯•æ ¹æ®æ‰©å±•å
    mime_type, _ = mimetypes.guess_type(str(file_path))
    
    if mime_type:
        return mime_type
    
    # æ ¹æ®æ‰©å±•åæ‰‹åŠ¨æ˜ å°„
    ext = file_path.suffix.lower()
    mime_mapping = {
        '.m4a': 'audio/mp4',
        '.mp4': 'audio/mp4',
        '.mp3': 'audio/mpeg',
        '.aac': 'audio/aac',
        '.webm': 'audio/webm',
        '.ogg': 'audio/ogg',
        '.wav': 'audio/wav',
        '.flac': 'audio/flac',
        '': 'audio/mp4'  # æ— æ‰©å±•åé»˜è®¤ä¸ºaudio/mp4
    }
    
    return mime_mapping.get(ext, 'audio/mp4')  # é»˜è®¤ä½¿ç”¨audio/mp4

@app.route('/files/audio')
def serve_audio():
    """æä¾›éŸ³é¢‘æ–‡ä»¶æœåŠ¡"""
    video_id = request.args.get('id')
    if not video_id:
        abort(400, "Missing video id")
    
    # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€çš„éŸ³é¢‘æ–‡ä»¶æŸ¥æ‰¾é€»è¾‘
    audio_file = find_actual_audio_file(video_id)
    
    if not audio_file:
        logger.error(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_id}")
        abort(404, "Audio file not found")
    
    # è·å–æ­£ç¡®çš„MIMEç±»å‹
    mime_type = get_file_mime_type(audio_file)
    logger.info(f"ğŸµ æä¾›éŸ³é¢‘æ–‡ä»¶: {video_id}, æ–‡ä»¶: {audio_file.name}, MIME: {mime_type}")
    
    # æ”¯æŒRangeè¯·æ±‚
    return send_file(
        audio_file,
        mimetype=mime_type,
        as_attachment=False,
        conditional=True  # å¯ç”¨Rangeæ”¯æŒ
    )

@app.route('/files/subtitle')
def serve_subtitle():
    """æä¾›å­—å¹•æ–‡ä»¶æœåŠ¡"""
    video_id = request.args.get('id')
    if not video_id:
        abort(400, "Missing video id")
    
    subtitle_file = get_file_path(video_id, "subtitle")
    if not subtitle_file.exists():
        abort(404, "Subtitle file not found")
    
    logger.info(f"ğŸ“ æä¾›å­—å¹•æ–‡ä»¶: {video_id}")
    
    return send_file(
        subtitle_file,
        mimetype="text/plain",
        as_attachment=False
    )

@app.route('/info')
def get_video_info_api():
    """è·å–è§†é¢‘ä¿¡æ¯API"""
    video_id = request.args.get('id')
    if not video_id:
        abort(400, "Missing video id")
    
    info = get_video_info(video_id)
    if not info:
        return jsonify({"error": "Failed to get video info"}), 400
    
    return jsonify(info)

@app.route('/cancel', methods=['DELETE'])
def cancel_download():
    """å–æ¶ˆä¸‹è½½ä»»åŠ¡"""
    video_id = request.args.get('id')
    if not video_id:
        return jsonify({"error": "Missing video id"}), 400
    
    if video_id not in tasks:
        return jsonify({"error": "Task not found"}), 404
    
    task = tasks[video_id]
    
    if task.status in [TaskStatus.PENDING, TaskStatus.DOWNLOADING]:
        task.status = TaskStatus.CANCELLED
        task.message = "ä»»åŠ¡å·²å–æ¶ˆ"
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼ˆéé˜»å¡ï¼‰
        if video_id in download_threads:
            thread = download_threads[video_id]
            if thread.is_alive():
                # ç»™çº¿ç¨‹ä¸€äº›æ—¶é—´è‡ªè¡Œç»“æŸ
                thread.join(timeout=2.0)
        
        logger.info(f"âš ï¸ ä¸‹è½½ä»»åŠ¡å·²å–æ¶ˆ: {video_id}")
        
        return jsonify({
            "message": "Task cancelled",
            "status": task.status.value
        })
    else:
        return jsonify({
            "message": f"Cannot cancel task in status: {task.status.value}",
            "status": task.status.value
        }), 400

@app.route('/api/cookies/status')
def cookies_status():
    """æ£€æŸ¥ cookies é…ç½®çŠ¶æ€"""
    cookies_configured = COOKIES_FILE.exists()
    cookies_info = {
        "cookies_configured": cookies_configured,
        "cookies_file": str(COOKIES_FILE),
    }
    
    if cookies_configured:
        try:
            file_size = COOKIES_FILE.stat().st_size
            file_mtime = datetime.fromtimestamp(COOKIES_FILE.stat().st_mtime)
            cookies_info["file_size"] = file_size
            cookies_info["last_modified"] = file_mtime.isoformat()
            cookies_info["status"] = "âœ… Cookies æ–‡ä»¶å·²é…ç½®"
        except Exception as e:
            cookies_info["status"] = f"âš ï¸ æ— æ³•è¯»å– Cookies æ–‡ä»¶: {e}"
    else:
        cookies_info["status"] = "âŒ æœªæ‰¾åˆ° Cookies æ–‡ä»¶"
    
    cookies_info["help"] = "å¦‚æœé‡åˆ° HTTP 403 é”™è¯¯ï¼Œè¯·å°è¯•ï¼š\n1. é‡æ–°å¯¼å‡ºæ–°çš„ Cookiesï¼ˆæ—§ Cookies å¯èƒ½å·²è¿‡æœŸï¼‰\n2. ç¡®ä¿ Cookies æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆNetscape æ ¼å¼ï¼‰\n3. æ£€æŸ¥ Cookies æ–‡ä»¶æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„ä¼šè¯ä¿¡æ¯\n4. é‡å¯æœåŠ¡å™¨"
    
    return jsonify(cookies_info)

@app.route('/api/cookies/diagnose')
def cookies_diagnose():
    """è¯Šæ–­ Cookies é—®é¢˜"""
    diagnosis = {
        "timestamp": datetime.now().isoformat(),
        "cookies_file_exists": COOKIES_FILE.exists(),
    }
    
    if COOKIES_FILE.exists():
        try:
            with open(COOKIES_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.strip().split('\n')
                diagnosis["file_size"] = len(content)
                diagnosis["line_count"] = len(lines)
                diagnosis["is_netscape_format"] = lines[0].startswith('#') if lines else False
                diagnosis["has_youtube_cookies"] = any('youtube' in line.lower() for line in lines)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ cookies
                valid_cookies = [l for l in lines if l.strip() and not l.startswith('#')]
                diagnosis["valid_cookie_count"] = len(valid_cookies)
                
                if diagnosis["valid_cookie_count"] > 0:
                    diagnosis["status"] = "âœ… Cookies æ–‡ä»¶çœ‹èµ·æ¥æœ‰æ•ˆ"
                else:
                    diagnosis["status"] = "âŒ Cookies æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®"
        except Exception as e:
            diagnosis["status"] = f"âŒ æ— æ³•è¯»å– Cookies æ–‡ä»¶: {e}"
    else:
        diagnosis["status"] = "âŒ Cookies æ–‡ä»¶ä¸å­˜åœ¨"
    
    return jsonify(diagnosis)

@app.route('/api/test/youtube/<video_id>')
def test_youtube_connection(video_id):
    """æµ‹è¯• YouTube è¿æ¥å’Œ yt-dlp é…ç½®"""
    test_result = {
        "timestamp": datetime.now().isoformat(),
        "video_id": video_id,
        "tests": {}
    }
    
    try:
        # æµ‹è¯• 1: åŸºç¡€è¿æ¥
        test_result["tests"]["basic_connection"] = {
            "status": "testing",
            "message": "æ­£åœ¨æµ‹è¯•åŸºç¡€è¿æ¥..."
        }
        
        ydl_opts = {
            **get_common_ydl_opts(),
            'quiet': True,
            'no_warnings': True,
            'extract_flat': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(f'https://www.youtube.com/watch?v={video_id}', download=False)
            
        test_result["tests"]["basic_connection"] = {
            "status": "âœ… æˆåŠŸ",
            "message": "å¯ä»¥è·å–è§†é¢‘ä¿¡æ¯",
            "video_title": info.get('title', 'N/A'),
            "duration": info.get('duration', 'N/A'),
            "formats_available": len(info.get('formats', []))
        }
        
        # æµ‹è¯• 2: éŸ³é¢‘æ ¼å¼å¯ç”¨æ€§
        test_result["tests"]["audio_formats"] = {
            "status": "âœ… æˆåŠŸ",
            "message": "éŸ³é¢‘æ ¼å¼å¯ç”¨",
            "audio_formats_count": len([f for f in info.get('formats', []) if f.get('vcodec') == 'none'])
        }
        
        test_result["overall_status"] = "âœ… YouTube è¿æ¥æ­£å¸¸"
        
    except Exception as e:
        error_msg = str(e)
        test_result["tests"]["basic_connection"] = {
            "status": "âŒ å¤±è´¥",
            "error": error_msg
        }
        
        # è¯Šæ–­é”™è¯¯ç±»å‹
        if "403" in error_msg:
            test_result["diagnosis"] = "ğŸš« HTTP 403 é”™è¯¯ - YouTube æ‹’ç»è®¿é—®"
            test_result["solutions"] = [
                "1. æ£€æŸ¥ Cookies æ˜¯å¦è¿‡æœŸ: curl http://localhost:5000/api/cookies/diagnose",
                "2. é‡æ–°å¯¼å‡º YouTube Cookies (éœ€è¦æ–°çš„ç™»å½•ä¼šè¯)",
                "3. æ£€æŸ¥ IP æ˜¯å¦è¢«é™åˆ¶ (ç­‰å¾… 1-2 å°æ—¶åé‡è¯•)",
                "4. å°è¯•ä½¿ç”¨ VPN æˆ–ä»£ç†"
            ]
        elif "bot" in error_msg.lower() or "sign in" in error_msg.lower():
            test_result["diagnosis"] = "ğŸ¤– æœºå™¨äººéªŒè¯é”™è¯¯"
            test_result["solutions"] = [
                "1. å¯¼å‡ºæœ‰æ•ˆçš„ YouTube Cookies",
                "2. ç¡®ä¿ Cookies æ–‡ä»¶ä½ç½®æ­£ç¡®: ./youtube_cookies.txt",
                "3. é‡å¯æœåŠ¡"
            ]
        else:
            test_result["diagnosis"] = f"âŒ å…¶ä»–é”™è¯¯: {error_msg}"
            test_result["solutions"] = [
                "1. æ£€æŸ¥ç½‘ç»œè¿æ¥",
                "2. æ£€æŸ¥ yt-dlp æ˜¯å¦æœ€æ–°: pip install --upgrade yt-dlp",
                "3. æŸ¥çœ‹å®Œæ•´æ—¥å¿—: tail -f youtube_download.log"
            ]
        
        test_result["overall_status"] = "âŒ YouTube è¿æ¥å¤±è´¥"
    
    return jsonify(test_result)

@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥"""
    active_tasks = sum(1 for task in tasks.values() 
                      if task.status in [TaskStatus.PENDING, TaskStatus.DOWNLOADING])
    
    completed_tasks = sum(1 for task in tasks.values() 
                         if task.status == TaskStatus.COMPLETED)
    
    failed_tasks = sum(1 for task in tasks.values() 
                      if task.status == TaskStatus.FAILED)
    
    # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
    download_files_count = len(list(DOWNLOAD_DIR.glob("*")))
    cache_files_count = len(list(CACHE_DIR.glob("*")))
    
    return jsonify({
        "status": "healthy",
        "service": "YouTube Audio Download Server with yt-dlp Data API",
        "version": "3.0.0",
        "tasks": {
            "active": active_tasks,
            "completed": completed_tasks,
            "failed": failed_tasks,
            "total": len(tasks)
        },
        "files": {
            "download_files": download_files_count,
            "cache_files": cache_files_count
        },
        "directories": {
            "download_dir": str(DOWNLOAD_DIR.absolute()),
            "cache_dir": str(CACHE_DIR.absolute())
        },
        "cache_expire_hours": CACHE_EXPIRE_HOURS,
        "features": {
            "intelligent_file_reuse": "æ™ºèƒ½æ–‡ä»¶å¤ç”¨ - å·²ä¸‹è½½æ–‡ä»¶æ°¸ä¹…æœ‰æ•ˆï¼Œæ— éœ€é‡å¤ä¸‹è½½",
            "smart_task_management": "æ™ºèƒ½ä»»åŠ¡ç®¡ç†ï¼Œé¿å…é‡å¤ä»»åŠ¡",
            "memory_cleanup": "å®šæ—¶æ¸…ç†è¿‡æœŸä»»åŠ¡è®°å½•ï¼ˆ12å°æ—¶ï¼‰",
            "disk_cleanup": "å®šæ—¶æ¸…ç†è¿‡æœŸæ–‡ä»¶ï¼ˆ12å°æ—¶ï¼‰"
        }
    })

@app.route('/')
def index():
    """æœåŠ¡ä¿¡æ¯é¡µé¢"""
    return jsonify({
        "service": "YouTube Audio Download Server with yt-dlp Data API",
        "version": "3.0.0",
        "description": "ä½¿ç”¨yt-dlpæ›¿ä»£YouTube Data API v3ï¼Œæ— é…é¢é™åˆ¶",
        "features": [
            "å®Œæ•´ä¸‹è½½mp3éŸ³é¢‘å’Œvttå­—å¹•",
            "æ”¯æŒæ–­ç‚¹ç»­ä¼ ",
            "è‡ªåŠ¨ç¼“å­˜ç®¡ç†(12å°æ—¶)",
            "HTTP Rangeè¯·æ±‚æ”¯æŒ",
            "ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†",
            "ä½¿ç”¨yt-dlpè·å–YouTubeæ•°æ®ï¼Œæ— APIé…é¢é™åˆ¶",
            "æ™ºèƒ½ç¼“å­˜é¢‘é“å’Œè§†é¢‘ä¿¡æ¯",
            "æ”¯æŒå¤šç§é¢‘é“æ ‡è¯†æ ¼å¼(@username, é¢‘é“IDç­‰)",
            "æ— éœ€ffmpegä¾èµ–ï¼Œé€‚åˆä½é…ç½®æœåŠ¡å™¨"
        ],
        "endpoints": {
            "download_related": {
                "POST /download?id=VIDEO_ID": "å¼€å§‹ä¸‹è½½ä»»åŠ¡",
                "GET /status?id=VIDEO_ID": "è·å–ä¸‹è½½çŠ¶æ€",
                "GET /files/audio?id=VIDEO_ID": "è·å–éŸ³é¢‘æ–‡ä»¶",
                "GET /files/subtitle?id=VIDEO_ID": "è·å–å­—å¹•æ–‡ä»¶", 
                "GET /info?id=VIDEO_ID": "è·å–è§†é¢‘ä¿¡æ¯",
                "DELETE /cancel?id=VIDEO_ID": "å–æ¶ˆä¸‹è½½ä»»åŠ¡"
            },
            "youtube_data_api": {
                "GET /api/channel/info?id=CHANNEL_ID_OR_USERNAME": "è·å–é¢‘é“ä¿¡æ¯",
                "GET /api/channel/videos?id=CHANNEL_ID&limit=20": "è·å–é¢‘é“è§†é¢‘åˆ—è¡¨",
                "GET /api/video/info?id=VIDEO_ID": "è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯",
                "GET /api/search/channel?q=QUERY&limit=10": "æœç´¢é¢‘é“"
            },
            "utility": {
                "GET /health": "å¥åº·æ£€æŸ¥",
                "GET /debug/files?id=VIDEO_ID": "è°ƒè¯•æ–‡ä»¶ä¿¡æ¯",
                "GET /fix/files?id=VIDEO_ID": "ä¿®å¤æ–‡ä»¶æ‰©å±•å",
                "POST /admin/cleanup": "æ‰‹åŠ¨è§¦å‘æ¸…ç†æ“ä½œ"
            }
        },
        "supported_channel_formats": [
            "@username (æ¨è)",
            "é¢‘é“ID (UCxxxxxxxx)",
            "é¢‘é“ç”¨æˆ·å",
            "é¢‘é“è‡ªå®šä¹‰URL"
        ]
    })

@app.route('/debug/files')
def debug_files():
    """è°ƒè¯•ç«¯ç‚¹ï¼šæ£€æŸ¥æ–‡ä»¶ä¿¡æ¯"""
    video_id = request.args.get('id')
    if not video_id:
        return jsonify({"error": "Missing video id"}), 400
    
    debug_info = {
        "video_id": video_id,
        "files": []
    }
    
    # æ£€æŸ¥ä¸‹è½½ç›®å½•ä¸­çš„æ‰€æœ‰ç›¸å…³æ–‡ä»¶
    safe_id = hashlib.md5(video_id.encode()).hexdigest()[:12]
    for file_path in DOWNLOAD_DIR.glob(f"{safe_id}_{video_id}*"):
        if file_path.is_file():
            try:
                stat = file_path.stat()
                mime_type = get_file_mime_type(file_path)
                
                file_info = {
                    "name": file_path.name,
                    "path": str(file_path),
                    "size": stat.st_size,
                    "size_mb": round(stat.st_size / 1024 / 1024, 2),
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "extension": file_path.suffix,
                    "mime_type": mime_type,
                    "exists": True
                }
                debug_info["files"].append(file_info)
            except Exception as e:
                debug_info["files"].append({
                    "name": file_path.name,
                    "error": str(e),
                    "exists": file_path.exists()
                })
    
    # æ£€æŸ¥ä»»åŠ¡ä¿¡æ¯
    if video_id in tasks:
        task = tasks[video_id]
        debug_info["task"] = {
            "status": task.status.value,
            "audio_file": task.audio_file,
            "subtitle_file": task.subtitle_file,
            "progress": task.progress,
            "message": task.message
        }
    
    return jsonify(debug_info)

@app.route('/fix/files')
def fix_files():
    """ä¿®å¤ç«¯ç‚¹ï¼šä¸ºæ— æ‰©å±•åçš„éŸ³é¢‘æ–‡ä»¶æ·»åŠ æ‰©å±•å"""
    video_id = request.args.get('id')
    if not video_id:
        return jsonify({"error": "Missing video id"}), 400
    
    result = {
        "video_id": video_id,
        "actions": []
    }
    
    # æŸ¥æ‰¾æ— æ‰©å±•åçš„éŸ³é¢‘æ–‡ä»¶
    safe_id = hashlib.md5(video_id.encode()).hexdigest()[:12]
    base_path = DOWNLOAD_DIR / f"{safe_id}_{video_id}"
    
    if base_path.exists() and base_path.is_file():
        # æ‰¾åˆ°æ— æ‰©å±•åæ–‡ä»¶
        target_path = base_path.with_suffix('.mp3')
        
        if not target_path.exists():
            try:
                shutil.move(str(base_path), str(target_path))
                result["actions"].append({
                    "action": "renamed",
                    "from": base_path.name,
                    "to": target_path.name,
                    "success": True
                })
                
                # æ›´æ–°ä»»åŠ¡è®°å½•
                if video_id in tasks:
                    tasks[video_id].audio_file = str(target_path)
                    result["actions"].append({
                        "action": "updated_task",
                        "audio_file": str(target_path),
                        "success": True
                    })
                
            except Exception as e:
                result["actions"].append({
                    "action": "rename_failed",
                    "error": str(e),
                    "success": False
                })
        else:
            result["actions"].append({
                "action": "target_exists",
                "message": f"{target_path.name} already exists",
                "success": False
            })
    else:
        result["actions"].append({
            "action": "not_found",
            "message": f"No file found: {base_path.name}",
            "success": False
        })
    
    return jsonify(result)

@app.route('/admin/cleanup', methods=['POST'])
def manual_cleanup():
    """æ‰‹åŠ¨è§¦å‘æ¸…ç†ï¼ˆç®¡ç†ç«¯ç‚¹ï¼‰"""
    try:
        logger.info("ğŸ§¹ æ‰‹åŠ¨è§¦å‘æ¸…ç†æ“ä½œ...")
        
        # æ‰§è¡Œæ¸…ç†
        old_task_count = len(tasks)
        cleanup_old_files()
        new_task_count = len(tasks)
        
        cleaned_tasks = old_task_count - new_task_count
        
        # ç»Ÿè®¡å½“å‰çŠ¶æ€
        active_tasks = sum(1 for task in tasks.values() 
                          if task.status in [TaskStatus.PENDING, TaskStatus.DOWNLOADING])
        completed_tasks = sum(1 for task in tasks.values() 
                             if task.status == TaskStatus.COMPLETED)
        
        return jsonify({
            "status": "success",
            "message": "æ‰‹åŠ¨æ¸…ç†å®Œæˆ",
            "cleanup_results": {
                "tasks_cleaned": cleaned_tasks,
                "remaining_tasks": new_task_count,
                "active_tasks": active_tasks,
                "completed_tasks": completed_tasks
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ æ‰‹åŠ¨æ¸…ç†å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": f"æ¸…ç†å¤±è´¥: {str(e)}"
        }), 500

def cleanup_timer():
    """å®šæœŸæ¸…ç†å®šæ—¶å™¨"""
    while True:
        time.sleep(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
        cleanup_old_files()

if __name__ == '__main__':
    logger.info("ğŸš€ Starting YouTube Audio Download Server with yt-dlp Data API...")
    logger.info("ğŸ“ Download directory: " + str(DOWNLOAD_DIR.absolute()))
    logger.info("ğŸ“¦ Cache directory: " + str(CACHE_DIR.absolute()))
    logger.info("â° Cache expiry: " + str(CACHE_EXPIRE_HOURS) + " hours")
    logger.info("ğŸ’¡ ffmpeg is optional - service works without it (may have format limitations)")
    logger.info("ğŸ”— API endpoints:")
    logger.info("   # ä¸‹è½½ç›¸å…³")
    logger.info("   POST /download?id=VIDEO_ID   - Start download task")
    logger.info("   GET /status?id=VIDEO_ID      - Get download status")
    logger.info("   GET /files/audio?id=VIDEO_ID - Serve audio file")
    logger.info("   GET /files/subtitle?id=VIDEO_ID - Serve subtitle file")
    logger.info("   GET /info?id=VIDEO_ID        - Get video metadata")
    logger.info("   DELETE /cancel?id=VIDEO_ID   - Cancel download task")
    logger.info("   # YouTubeæ•°æ®è·å–ï¼ˆæ›¿ä»£YouTube Data API v3ï¼‰")
    logger.info("   GET /api/channel/info?id=CHANNEL_ID_OR_USERNAME - Get channel info")
    logger.info("   GET /api/channel/videos?id=CHANNEL_ID&limit=20  - Get channel videos")
    logger.info("   GET /api/video/info?id=VIDEO_ID                 - Get video info")
    logger.info("   GET /api/search/channel?q=QUERY&limit=10        - Search channels")
    logger.info("   # å·¥å…·")
    logger.info("   GET /health                  - Health check")
    logger.info("   GET /debug/files?id=VIDEO_ID - Debug file information")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import yt_dlp
        import flask
        logger.info("âœ… All dependencies are available")
        logger.info(f"ğŸ“¦ yt-dlp version: {yt_dlp.version.__version__}")
    except ImportError as e:
        logger.error(f"âŒ Missing dependency: {e}")
        logger.error("ğŸ’¡ Please install: pip install flask yt-dlp")
        sys.exit(1)
    
    # å¯åŠ¨æ¸…ç†å®šæ—¶å™¨
    cleanup_thread = threading.Thread(target=cleanup_timer, daemon=True)
    cleanup_thread.start()
    logger.info("ğŸ§¹ Cleanup timer started")
    
    # å¯åŠ¨æœåŠ¡å™¨
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)